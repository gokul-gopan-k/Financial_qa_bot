{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) Model for QA Bot on P&L Data\n",
    "\n",
    "### Problem Statement:\n",
    "Develop a Retrieval-Augmented Generation (RAG) model for a Question Answering (QA) bot that can\n",
    "process financial terms and insights from a Profit & Loss (P&L) table extracted from PDF documents.\n",
    "\n",
    "### Task Requirements:\n",
    "\n",
    "- Implement a RAG-based model to handle questions related to a P&L table extracted fromPDF documents.\n",
    "- Use a vector database (such as Pinecone) to store and retrieve document embeddings of financial terms and data points efficiently.\n",
    "- Parse P&L data from PDF documents into a structured format, such as tables or key-value pairs, before storing embeddings.\n",
    "- Test the model with several financial queries and show how accurately it retrieves and generates responses from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENTS\n",
    "- Imports and setting device\n",
    "- Parsing PDF file and preprocessing\n",
    "- Emdedding genertion and Vectorbase creation\n",
    "- RAG pipeline\n",
    "- Retrievel \n",
    "- Augment and generate\n",
    "- Testing with queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulgopank/Documents/Sample_set/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import camelot\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting device\n",
    "\n",
    "GPU if available is enabled for faster training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing PDF file and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First need to extract the relevant pages that could have the profit loss table. The PL table usually contains the words “Statement of Profit and Loss\" , \"Revenue\" and \"Expenses”. This logic is used to extract the relevant pages. Another point is that the “Contents” page which appear in beginning of the document will also be having these terms. Hence the page with PL table will be the second one having all the said words. This logic is used to extract the correct page with PL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found relevant content on page 1\n",
      "Found relevant content on page 3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def extract_page_no(pdf_path):\n",
    "    relevant_pages=[]\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            text = page.extract_text()\n",
    "            # Check if \"Profit and Loss,Renenue and Expenses.\" is in the page text\n",
    "            if \"Statement of Profit and Loss\" in text and \"Revenue\" in text and \"Expenses\" in text:\n",
    "                # Print the page number\n",
    "                print(f\"Found relevant content on page {i}\")\n",
    "                relevant_pages.append(i)\n",
    "        return str(relevant_pages[1])\n",
    "\n",
    "# Example usage\n",
    "pdf_path = 'Sample Financial Statement.pdf'\n",
    "x = extract_page_no(pdf_path)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table is extracted using camelot library. It is then preprocessed to removed unwanted rows and column. The columns are also edited to make a coherent structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found relevant content on page 1\n",
      "Found relevant content on page 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condensed Consolidated Statement of Profit and Loss for the</th>\n",
       "      <th>Three months ended March 31,2024</th>\n",
       "      <th>Three months ended March 31,2023</th>\n",
       "      <th>Year ended March 31,2024</th>\n",
       "      <th>Year ended March 31,2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revenue from operations</td>\n",
       "      <td>37,923</td>\n",
       "      <td>37,441</td>\n",
       "      <td>153,670</td>\n",
       "      <td>146,767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other income, net</td>\n",
       "      <td>2,729</td>\n",
       "      <td>671</td>\n",
       "      <td>4,711</td>\n",
       "      <td>2,701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total income</td>\n",
       "      <td>40,652</td>\n",
       "      <td>38,112</td>\n",
       "      <td>158,381</td>\n",
       "      <td>149,468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expenses</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Employee benefit expenses</td>\n",
       "      <td>20,393</td>\n",
       "      <td>20,311</td>\n",
       "      <td>82,620</td>\n",
       "      <td>78,359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cost of technical sub-contractors</td>\n",
       "      <td>2,967</td>\n",
       "      <td>3,116</td>\n",
       "      <td>12,232</td>\n",
       "      <td>14,062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Travel expenses</td>\n",
       "      <td>471</td>\n",
       "      <td>426</td>\n",
       "      <td>1,759</td>\n",
       "      <td>1,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cost of software packages and others</td>\n",
       "      <td>3,687</td>\n",
       "      <td>2,886</td>\n",
       "      <td>13,515</td>\n",
       "      <td>10,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Communication expenses</td>\n",
       "      <td>147</td>\n",
       "      <td>171</td>\n",
       "      <td>677</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Consultancy and professional charges</td>\n",
       "      <td>489</td>\n",
       "      <td>387</td>\n",
       "      <td>1,726</td>\n",
       "      <td>1,684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Depreciation and amortization expenses</td>\n",
       "      <td>1,163</td>\n",
       "      <td>1,121</td>\n",
       "      <td>4,678</td>\n",
       "      <td>4,225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Finance cost</td>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>470</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Other expenses</td>\n",
       "      <td>985</td>\n",
       "      <td>1,146</td>\n",
       "      <td>4,716</td>\n",
       "      <td>4,392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Total expenses</td>\n",
       "      <td>30,412</td>\n",
       "      <td>29,646</td>\n",
       "      <td>122,393</td>\n",
       "      <td>116,146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Profit before tax</td>\n",
       "      <td>10,240</td>\n",
       "      <td>8,466</td>\n",
       "      <td>35,988</td>\n",
       "      <td>33,322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tax expense:</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Current tax</td>\n",
       "      <td>1,173</td>\n",
       "      <td>2,260</td>\n",
       "      <td>8,390</td>\n",
       "      <td>9,287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Deferred tax</td>\n",
       "      <td>1,092</td>\n",
       "      <td>72</td>\n",
       "      <td>1,350                                   (73)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Profit for the period</td>\n",
       "      <td>7,975</td>\n",
       "      <td>6,134</td>\n",
       "      <td>26,248</td>\n",
       "      <td>24,108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Other comprehensive income</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Items that will not be reclassified subsequent...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Remeasurement of the net defined benefit liabi...</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Equity instruments through other comprehensive...</td>\n",
       "      <td>(12)</td>\n",
       "      <td>(15)</td>\n",
       "      <td>19                                     (7)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Items that will be reclassified subsequently t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Fair value changes on derivatives designated a...</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>11                                     (7)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Exchange differences on translation of foreign...</td>\n",
       "      <td>(231)</td>\n",
       "      <td>61</td>\n",
       "      <td>226</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fair value changes on investments, net</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>144                                 (256)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>(166)</td>\n",
       "      <td>139</td>\n",
       "      <td>381</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Total other comprehensive income /(loss), net ...</td>\n",
       "      <td>(152)</td>\n",
       "      <td>149</td>\n",
       "      <td>520</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Total comprehensive income for the period</td>\n",
       "      <td>7,823</td>\n",
       "      <td>6,283</td>\n",
       "      <td>26,768</td>\n",
       "      <td>24,622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Profit attributable to:</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Owners of the Company</td>\n",
       "      <td>7,969</td>\n",
       "      <td>6,128</td>\n",
       "      <td>26,233</td>\n",
       "      <td>24,095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  Condensed Consolidated Statement of Profit and Loss for the  \\\n",
       "0                             Revenue from operations            \n",
       "1                                   Other income, net            \n",
       "2                                        Total income            \n",
       "3                                            Expenses            \n",
       "4                           Employee benefit expenses            \n",
       "5                   Cost of technical sub-contractors            \n",
       "6                                     Travel expenses            \n",
       "7                Cost of software packages and others            \n",
       "8                              Communication expenses            \n",
       "9                Consultancy and professional charges            \n",
       "10             Depreciation and amortization expenses            \n",
       "11                                       Finance cost            \n",
       "12                                     Other expenses            \n",
       "13                                     Total expenses            \n",
       "14                                  Profit before tax            \n",
       "15                                       Tax expense:            \n",
       "16                                        Current tax            \n",
       "17                                       Deferred tax            \n",
       "18                              Profit for the period            \n",
       "19                         Other comprehensive income            \n",
       "20  Items that will not be reclassified subsequent...            \n",
       "21  Remeasurement of the net defined benefit liabi...            \n",
       "22  Equity instruments through other comprehensive...            \n",
       "23                                                               \n",
       "24  Items that will be reclassified subsequently t...            \n",
       "25  Fair value changes on derivatives designated a...            \n",
       "26  Exchange differences on translation of foreign...            \n",
       "27             Fair value changes on investments, net            \n",
       "28                                                               \n",
       "29  Total other comprehensive income /(loss), net ...            \n",
       "30          Total comprehensive income for the period            \n",
       "31                            Profit attributable to:            \n",
       "32                              Owners of the Company            \n",
       "\n",
       "0  Three months ended March 31,2024 Three months ended March 31,2023  \\\n",
       "0                            37,923                           37,441   \n",
       "1                             2,729                              671   \n",
       "2                            40,652                           38,112   \n",
       "3                                                                      \n",
       "4                            20,393                           20,311   \n",
       "5                             2,967                            3,116   \n",
       "6                               471                              426   \n",
       "7                             3,687                            2,886   \n",
       "8                               147                              171   \n",
       "9                               489                              387   \n",
       "10                            1,163                            1,121   \n",
       "11                              110                               82   \n",
       "12                              985                            1,146   \n",
       "13                           30,412                           29,646   \n",
       "14                           10,240                            8,466   \n",
       "15                                                                     \n",
       "16                            1,173                            2,260   \n",
       "17                            1,092                               72   \n",
       "18                            7,975                            6,134   \n",
       "19                                                                     \n",
       "20                                                                     \n",
       "21                               26                               25   \n",
       "22                             (12)                             (15)   \n",
       "23                               14                               10   \n",
       "24                                                                     \n",
       "25                               28                               36   \n",
       "26                            (231)                               61   \n",
       "27                               37                               42   \n",
       "28                            (166)                              139   \n",
       "29                            (152)                              149   \n",
       "30                            7,823                            6,283   \n",
       "31                                                                     \n",
       "32                            7,969                            6,128   \n",
       "\n",
       "0                       Year ended March 31,2024  \\\n",
       "0                                       153,670    \n",
       "1                                         4,711    \n",
       "2                                       158,381    \n",
       "3                                                  \n",
       "4                                        82,620    \n",
       "5                                        12,232    \n",
       "6                                         1,759    \n",
       "7                                        13,515    \n",
       "8                                           677    \n",
       "9                                         1,726    \n",
       "10                                        4,678    \n",
       "11                                          470    \n",
       "12                                        4,716    \n",
       "13                                      122,393    \n",
       "14                                       35,988    \n",
       "15                                                 \n",
       "16                                        8,390    \n",
       "17  1,350                                   (73)   \n",
       "18                                       26,248    \n",
       "19                                                 \n",
       "20                                                 \n",
       "21                                          120    \n",
       "22    19                                     (7)   \n",
       "23                                          139    \n",
       "24                                                 \n",
       "25    11                                     (7)   \n",
       "26                                          226    \n",
       "27     144                                 (256)   \n",
       "28                                          381    \n",
       "29                                          520    \n",
       "30                                       26,768    \n",
       "31                                                 \n",
       "32                                       26,233    \n",
       "\n",
       "0                 Year ended March 31,2023  \n",
       "0                                  146,767  \n",
       "1                                    2,701  \n",
       "2                                  149,468  \n",
       "3                                     None  \n",
       "4                                   78,359  \n",
       "5                                   14,062  \n",
       "6                                    1,525  \n",
       "7                                   10,902  \n",
       "8                                      713  \n",
       "9                                    1,684  \n",
       "10                                   4,225  \n",
       "11                                     284  \n",
       "12                                   4,392  \n",
       "13                                 116,146  \n",
       "14                                  33,322  \n",
       "15                                    None  \n",
       "16                                   9,287  \n",
       "17                                    None  \n",
       "18                                  24,108  \n",
       "19                                    None  \n",
       "20                                    None  \n",
       "21                                       8  \n",
       "22                                    None  \n",
       "23                                       1  \n",
       "24                                    None  \n",
       "25                                    None  \n",
       "26                                     776  \n",
       "27                                    None  \n",
       "28                                     513  \n",
       "29                                     514  \n",
       "30                                  24,622  \n",
       "31                                    None  \n",
       "32                                  24,095  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# PDF Extraction Function (adapt as needed for your specific PDF structure)\n",
    "def extract_profit_loss_tables(pdf_path,page):\n",
    "    tables = camelot.read_pdf(pdf_path, pages=page, flavor='stream')\n",
    "    if tables:\n",
    "        df = tables[0].df\n",
    "        df = df.iloc[2:]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.drop(index=[0, 1])\n",
    "        df[['Year ended March 31,2024', 'Year ended March 31,2023']] = df['Year ended March 31,'].str.split('\\n', expand=True)\n",
    "        df = df.drop(columns=['Note No.', 'Year ended March 31,'])\n",
    "        df.columns.values[1] = 'Three months ended March 31,2024'\n",
    "        df.columns.values[2] = 'Three months ended March 31,2023'\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No tables found on the specified page.\")\n",
    "        return pd.DataFrame() #Return empty dataframe to avoid errors\n",
    "    \n",
    "pdf_path=\"Sample Financial Statement.pdf\"\n",
    "pl_page = extract_page_no(pdf_path)\n",
    "pl_table=extract_profit_loss_tables(pdf_path,pl_page)\n",
    "pl_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emdedding genertion and Vectorbase creation\n",
    "\n",
    "Different open source vector base approaches were tried such as FAISS and Chromadb.\n",
    "ChromaDB is selected as it is designed for AI and Retrieval-Augmented Generation (RAG)applications.\n",
    "It is optimized for fast similarity search and can store, index, and retrieve embeddings efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChromaDB client is first initialised and create a collection named \"financial_data in the persistent\" database.\n",
    "Collections in ChromaDB are used to store vector data along with metadata.  This is where you would store vectors (e.g., embeddings of financial documents) and associated metadata (e.g., document IDs, timestamps, etc.).\n",
    "ChromaDB is a vector database designed to manage and store vector embeddings. It allows for efficient similarity search and retrieval of high-dimensional vectors, which is especially useful for applications like semantic search, machine learning, and natural language processing tasks. ChromaDB can handle storing, querying, and indexing embeddings, making it a useful tool for building systems that rely on vector search and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"financial_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'all-MiniLM-L6-v2' is used as pretrained embedding model from the SentenceTransformers library. It is a lightweight model based on Microsoft's MiniLM architecture, which balances speed and accuracy. Is is used to generate fixed-length vector dense representation  called embeddings from text.\n",
    "Each row is converted into a high-dimensional vector representation. These embeddings are stored as NumPy arrays. Finally the model is moved to the selected device for faster processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding and FAISS Setup\n",
    "embedding_model_name = 'all-MiniLM-L6-v2'\n",
    "embedding_model= SentenceTransformer(embedding_model_name)\n",
    "embedding_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next need to extract embeddings from tabular data andstore them in ChromaDB for efficient retrieval.\n",
    "\n",
    "First converts all DataFrame values to strings and aggregateeach row into a single space-separated string andconvert the rows into a list of strings .\n",
    "Use embedding model to generate vector embeddings for each row's text and converts the embeddings from a tensor to a NumPy array.\n",
    "Store each embedding in ChromaDB  using the row index as the unique identifier. Also store the original text as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store embeddings in ChromaDB\n",
    "def embed_and_store(df):\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    rows_text = df.astype(str).agg(' '.join, axis=1).tolist()\n",
    "    embeddings = embedding_model.encode(rows_text, convert_to_tensor=True, device=device).cpu().numpy()\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        collection.update(\n",
    "            ids=[str(i)],\n",
    "            embeddings=[embedding.tolist()],\n",
    "            metadatas=[{\"row\": rows_text[i]}]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32'], 'embeddings': array([[ 0.01805673, -0.05449116, -0.07919173, ..., -0.07793081,\n",
      "         0.04185454, -0.06581722],\n",
      "       [ 0.03873873, -0.05528183, -0.01569921, ..., -0.04594269,\n",
      "        -0.02963915, -0.04241281],\n",
      "       [ 0.06413926, -0.03403589,  0.00919265, ..., -0.06510878,\n",
      "        -0.01722785, -0.08938234],\n",
      "       ...,\n",
      "       [-0.04281837, -0.04527131,  0.00536274, ..., -0.08641743,\n",
      "        -0.02762058, -0.05120561],\n",
      "       [-0.00147541,  0.08183503, -0.12176751, ..., -0.11915076,\n",
      "         0.01085957,  0.0036928 ],\n",
      "       [-0.04783782, -0.04752753, -0.05690166, ..., -0.0609794 ,\n",
      "         0.0648248 , -0.00879265]]), 'documents': None, 'uris': None, 'data': None, 'metadatas': [{'row': 'Revenue from operations 37,923 37,441 153,670                            146,767'}, {'row': 'Other income, net 2,729 671 4,711                                2,701'}, {'row': 'Total income 40,652 38,112 158,381                            149,468'}, {'row': 'Expenses    None'}, {'row': 'Employee benefit expenses 20,393 20,311 82,620                              78,359'}, {'row': 'Cost of technical sub-contractors 2,967 3,116 12,232                              14,062'}, {'row': 'Travel expenses 471 426 1,759                                1,525'}, {'row': 'Cost of software packages and others 3,687 2,886 13,515                              10,902'}, {'row': 'Communication expenses 147 171 677                                   713'}, {'row': 'Consultancy and professional charges 489 387 1,726                                1,684'}, {'row': 'Depreciation and amortization expenses 1,163 1,121 4,678                                4,225'}, {'row': 'Finance cost 110 82 470                                   284'}, {'row': 'Other expenses 985 1,146 4,716                                4,392'}, {'row': 'Total expenses 30,412 29,646 122,393                            116,146'}, {'row': 'Profit before tax 10,240 8,466 35,988                              33,322'}, {'row': 'Tax expense:    None'}, {'row': 'Current tax 1,173 2,260 8,390                                9,287'}, {'row': 'Deferred tax 1,092 72 1,350                                   (73) None'}, {'row': 'Profit for the period 7,975 6,134 26,248                              24,108'}, {'row': 'Other comprehensive income    None'}, {'row': 'Items that will not be reclassified subsequently to profit or loss    None'}, {'row': 'Remeasurement of the net defined benefit liability/asset, net 26 25 120                                       8'}, {'row': 'Equity instruments through other comprehensive income, net (12) (15) 19                                     (7) None'}, {'row': ' 14 10 139                                       1'}, {'row': 'Items that will be reclassified subsequently to profit or loss    None'}, {'row': 'Fair value changes on derivatives designated as cash flow hedge, net 28 36 11                                     (7) None'}, {'row': 'Exchange differences on translation of foreign operations (231) 61 226                                   776'}, {'row': 'Fair value changes on investments, net 37 42 144                                 (256) None'}, {'row': ' (166) 139 381                                   513'}, {'row': 'Total other comprehensive income /(loss), net of tax (152) 149 520                                   514'}, {'row': 'Total comprehensive income for the period 7,823 6,283 26,768                              24,622'}, {'row': 'Profit attributable to:    None'}, {'row': 'Owners of the Company 7,969 6,128 26,233                              24,095'}], 'included': [<IncludeEnum.embeddings: 'embeddings'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "stored_data = collection.get(include=[ 'embeddings','metadatas'])\n",
    "print(stored_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So embeddings have been sucessfully stored in chromadb database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG pipeline\n",
    "\n",
    "### Retrievel \n",
    "Next need to  use ChromaDB as a vector search index to retrieve the most relevant rows from a DataFrame based on the similarity between a query and the stored vector representations of data. Query is he input string for which you want to find relevant rows.\n",
    "\n",
    "Next need to retrieves the top k relevant rows from a DataFrame based on a similarity search using embeddings. For this encode the query, performs a vector search, extract matching rows, and filter the DataFrame to return only the relevant rows.\n",
    "\n",
    "First the query input is transformed into a query embedding using embedding model. The model takes the query string and encodes it into a tensor representation and then converted to a NumPy array.\n",
    "Next performs a query on a vector database giving top k closest matches in terms of similarity to the query embedding.\n",
    "Then get the filtered DataFrame, which contains only the rows whose combined text matches the retrieved rows from the vector search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Function\n",
    "def retrieve_relevant_rows(query, df, top_k=7):\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
    "    retrieved_texts = [res[\"row\"] for res in results[\"metadatas\"][0]]\n",
    "    return df[df.astype(str).agg(' '.join, axis=1).isin(retrieved_texts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment and generate\n",
    "\n",
    "Next need to select the generation model and prepare context according to its structure.\n",
    "Initially the TAPAS model, which stands for Tabular Pretrained Language Model, which a deep learning model designed for handling tabular data (data presented in tables, often seen in spreadsheets or databases). Unlike traditional language models like BERT or GPT, which are trained on textual data, TAPAS is specifically designed to interpret and answer questions about data presented in table form. But deepseek models are better open-source alternative and higher efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Inference\n",
    "llm_model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name, torch_dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next need to convert  content into a formatted string representation which can be input to the question answering llm model ie deepseek model.\n",
    "\n",
    "For this, first convert each row into a string representation where:column names (col) and corresponding values (value) are formatted as key-value pairs are then joined using a comma (, ) separator.The formatted row string is prefixed with \"Row {index}:\", indicating its original position in the DataFrame.\n",
    "The result is appended to the final list. Finally, all formatted rows are joined together using newline characters (\\n) to create a structured multi-line string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context Preparation\n",
    "def prepare_context(relevant_rows):\n",
    "    if relevant_rows.empty:\n",
    "        return \"\"\n",
    "    formatted_data = []\n",
    "    for index, row in relevant_rows.iterrows():\n",
    "        row_str = \", \".join(f\"{col}: {value}\" for col, value in row.items())\n",
    "        formatted_data.append(f\"Row {index}: {row_str}\")\n",
    "    \n",
    "    return \"\\n\".join(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, context):\n",
    "    if not context:\n",
    "        return \"No relevant context found.\"\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
    "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    inputs['input_ids'] = inputs['input_ids'].to(dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        with autocast(str(device)):\n",
    "            outputs = llm_model.generate(\n",
    "                **inputs, max_new_tokens=200, temperature=0.01, top_p=0.9, do_sample=True,\n",
    "                pad_token_id=llm_tokenizer.eos_token_id\n",
    "            )\n",
    "    return llm_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next need to take a question and a context as input and generates an answer based on the given context using the deepsake LLM. \n",
    "The steps are as follows:\n",
    "-Creating the Prompt:\n",
    "Construct a prompt string that follows a structured format:\"Context:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"This format helps the LLM understand that it needs to answer the question based on the given context.\n",
    "-Tokenizing the Input:\n",
    "The llm tokenizer converts the prompt into tokenized input tensors Also the input tensor  is explicitly cast to torch.long to ensure compatibility with the model.\n",
    "-Generating the Answer:\n",
    "autocast(device) is used for mixed precision to improve performance on GPUs. Generate text with the by setting parameters such as max no of tokens, padding and temperature.\n",
    "-Decoding the Output:\n",
    "The generated output tokens are converted back into text using llm tokenizer. The n remove unnecessary text before \"Answer:\" and trimming extra spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the RAG pipeline. We will get the relevant rows and answer to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate_answer(query, df):\n",
    "    relevant_rows = retrieve_relevant_rows(query, df)\n",
    "    context = prepare_context(relevant_rows)\n",
    "    return relevant_rows, answer_question(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process the uploaded PDF and query\n",
    "def process_pdf_and_query(pdf_file, query):\n",
    "    pl_page=extract_page_no(pdf_path)\n",
    "    # Extract tables from the uploaded PDF\n",
    "    pnl_table = extract_profit_loss_tables(pdf_file,pl_page)\n",
    "    embed_and_store(pnl_table)\n",
    "    relevant_rows,answer = retrieve_and_generate_answer(query, pnl_table)\n",
    "    return relevant_rows, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with queries\n",
    "\n",
    "Now lets test the model with some financialqueries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found relevant content on page 1\n",
      "Found relevant content on page 3\n",
      "3\n",
      "Answer: The gross profit for Q3 2024 is 7,975.\n"
     ]
    }
   ],
   "source": [
    "pdf_file=\"Sample Financial Statement.pdf\"\n",
    "query=\"What is the gross profit for Q3 2024?\"\n",
    "\n",
    "relevant_rows, answer = process_pdf_and_query(pdf_file, query)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relevant_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"How do the net income and operating expenses compare for Q1 2024?\"\n",
    "\n",
    "relevant_rows, answer = process_pdf_and_query(pdf_file, query)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relevant_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks completed:\n",
    "\n",
    "- Implemented a RAG-based model to handle questions related to a P&L table extracted fromPDF documents.\n",
    "- Used chromadb vectorbase to store and retrieve document embeddings of financial terms and data points efficiently.\n",
    "- Parsed P&L data from PDF documents into a structured format, such as tables or key-valuepairs, before storing embeddings.\n",
    "- Teste the model with several financial queries and show how accurately it retrieves and\n",
    "generates responses from the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
